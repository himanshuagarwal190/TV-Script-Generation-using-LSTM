{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Simpsons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM855vIG_f4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('moes_tavern_lines.txt')\n",
        "simpsons = file.read()\n",
        "file.close()\n",
        "simpsons = simpsons.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zr63fSML_f5D",
        "colab_type": "code",
        "outputId": "ceb7f455-8ae2-46b7-fb37-5b7829263898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(simpsons)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "305270"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28NiCKSr_f5I",
        "colab_type": "code",
        "outputId": "de6efb13-17fb-40c7-942f-f2e3d3d8d7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = sorted(set(simpsons))\n",
        "len(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K6aFNFI_f5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_int = dict((i,j) for (j,i) in enumerate(vocab))\n",
        "int_vocab = dict((i,j) for (i,j) in enumerate(vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vl2AT8Y_f5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = 20\n",
        "sequences = []\n",
        "target = []\n",
        "step = 1\n",
        "for i in range(0, len(simpsons) - seq_len, step):\n",
        "    sequences.append(simpsons[i:i+seq_len])\n",
        "    target.append(simpsons[i+seq_len])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfiGnI3F_f5Q",
        "colab_type": "code",
        "outputId": "08b9275a-b081-4acf-a30a-d7e4f30492ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(sequences[:5],'\\n', target[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[year date 1989] © t', 'year date 1989] © tw', 'ear date 1989] © twe', 'ar date 1989] © twen', 'r date 1989] © twent'] \n",
            " ['w', 'e', 'n', 't', 'i']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATnl2p9E_f5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_encoded = []\n",
        "tar_encoded = []\n",
        "for i in range(len(sequences)):\n",
        "    temp = []\n",
        "    for j in range(len(sequences[i])):\n",
        "        temp.append(vocab_int[sequences[i][j]])\n",
        "    seq_encoded.append(temp)\n",
        "for j in range(len(target)):\n",
        "    tar_encoded.append(vocab_int[target[j]])\n",
        "seq_encoded = np.asarray(seq_encoded)\n",
        "tar_encoded = np.asarray(tar_encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slsU193E_f5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "x = seq_encoded\n",
        "y = np_utils.to_categorical(tar_encoded, len(vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Szx1Iwy1_f5a",
        "colab_type": "code",
        "outputId": "0ff6a967-cb42-4a29-bc03-18dc2e63a1bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(x.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(305250, 20) (305250, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWcwCKNSIaKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Embedding, Dense, Dropout, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH5aU0rsQj2n",
        "colab_type": "code",
        "outputId": "cb30390f-2b61-4c30-bd8c-48c4d41ecc26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocab), 10, input_length=seq_len))\n",
        "model.add(LSTM(128, return_sequences=False))\n",
        "model.add(Dense(len(vocab)))\n",
        "model.add(Activation('softmax'))\n",
        "op = RMSprop(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam' , metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 20, 10)            650       \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 128)               71168     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 65)                8385      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 65)                0         \n",
            "=================================================================\n",
            "Total params: 80,203\n",
            "Trainable params: 80,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaEpJKGjRdhN",
        "colab_type": "code",
        "outputId": "51ccfaec-633f-419f-fb8d-5ad2da0c9570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit(x, y, epochs=10, batch_size=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "305250/305250 [==============================] - 122s 399us/step - loss: 1.3742 - acc: 0.5844\n",
            "Epoch 2/10\n",
            "305250/305250 [==============================] - 125s 411us/step - loss: 1.3590 - acc: 0.5890\n",
            "Epoch 3/10\n",
            "305250/305250 [==============================] - 117s 385us/step - loss: 1.3463 - acc: 0.5918\n",
            "Epoch 4/10\n",
            "305250/305250 [==============================] - 125s 408us/step - loss: 1.3338 - acc: 0.5956\n",
            "Epoch 5/10\n",
            "305250/305250 [==============================] - 116s 381us/step - loss: 1.3231 - acc: 0.5985\n",
            "Epoch 6/10\n",
            "305250/305250 [==============================] - 118s 388us/step - loss: 1.3131 - acc: 0.6008\n",
            "Epoch 7/10\n",
            "305250/305250 [==============================] - 130s 424us/step - loss: 1.3035 - acc: 0.6032\n",
            "Epoch 8/10\n",
            "305250/305250 [==============================] - 117s 384us/step - loss: 1.2951 - acc: 0.6064\n",
            "Epoch 9/10\n",
            "305250/305250 [==============================] - 117s 384us/step - loss: 1.2869 - acc: 0.6081\n",
            "Epoch 10/10\n",
            "305250/305250 [==============================] - 116s 379us/step - loss: 1.2797 - acc: 0.6099\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5f9304f550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSAD6oGlSXuZ",
        "colab_type": "code",
        "outputId": "119fb5bc-10f1-44c7-fd73-25403c37b7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "seed = \"As the two-slit experiment has shown\"\n",
        "seed = seed.lower()\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "for l in range(500):\n",
        "  text = seed[-seq_len:]\n",
        "  text_encoded = []\n",
        "  for i in range(len(text)):\n",
        "    text_encoded.append(vocab_int[text[i]])\n",
        "  text_encoded = np.asarray(text_encoded, dtype=float)\n",
        "  text_encoded = text_encoded.reshape(1,20)\n",
        "  pred = model.predict(text_encoded)\n",
        "  z = sample(pred[0])\n",
        "  z = int_vocab[z]\n",
        "  seed += z\n",
        "print(seed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "as the two-slit experiment has shown.\n",
            "bar_ra_bad any: i did the poot a bicks. too promocs of felmar little \"cance after off end it!\n",
            "homer_simpson: (napamly) food is sure the swell) you haven kermanthe he's file small kinds on the alwonch to the outss. i thank right till joy, you heard that for yaks the exp.\n",
            "homer_simpson: this is donswes-hilg now look just laugh, here'se wartle pennable.\n",
            "marge_simpson: (wishing up to my problemping that on a douph pen-tho festing like twan's boy? o'lloct with keep ofd never the tratent fan't did, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUH51K-1JhyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "    for i in range(len(text)):\n",
        "        temp = []\n",
        "        for j in range(len(text[i])):\n",
        "            temp.append(vocab_int[sequences[i][j]])\n",
        "        text_encoded.append(temp)\n",
        "'''\n",
        "'''\n",
        "    test = np.zeros((1,seq_len,len(vocab)), dtype=float)\n",
        "\n",
        "    for i in range(len(text_encoded)):\n",
        "      temp = []\n",
        "      for j in range(len(text_encoded[i])):\n",
        "        test[0,j,text_encoded[j]] = 1\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2vnphOXatfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/simpsons_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X77TMWaWbQ-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5KMMxnTCB3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Results\n",
        "\n",
        "10 Epochs, temperature=0.2:\n",
        "\n",
        "as the two-slit experiment has shown of my friends.\n",
        "moe_szyslak: (sings) what's the bar to the beer.\n",
        "moe_szyslak: (sobs) now i don't want to see many of a freety and i want to get the bar to be my friend.\n",
        "moe_szyslak: (singing) oh, i don't be name is a man a for the beer.\n",
        "moe_szyslak: (singing) oh, that's the bar.\n",
        "moe_szyslak: (sings) i got a hand of the said to the beer.\n",
        "moe_szyslak: (singing) oh yeah, i can't get the bar. (sighs) oh, that's the bar the bar the bar to me.\n",
        "moe_szyslak: (singing) hey, hey, hey, hey, hey, hey, hey,\n",
        "\n",
        "10 Epochs, temperature=0.7:\n",
        "\n",
        "as the two-slit experiment has shown-tive in the pretty to hold you one didchind here exper in this gares.\n",
        "homer_simpson: (chuckly) i wall me house a cootoue money little grank and for there to you of the too homer day homer.\n",
        "lenny_leonard: homer, you do you to par booksely woo how 'cause you conver.\n",
        "moe_szyslak: hey, homer, what's the strapers.\n",
        "homer_simpson: ....\n",
        "carl_carlson: she monnt it's pros of never with curenter the flow you and the flear and when you have been something here.\n",
        "homer_simpson: (prounds regor canchar to sall\n",
        "\n",
        "10 Epochs, temperature=1:\n",
        "\n",
        "as the two-slit experiment has shownardly? it's joth.\n",
        "moe_szyslak: yeah, i read too homer!\n",
        "homer_simpson: ohthoh. be walaterseal.\n",
        "\n",
        "\n",
        "prowds: yell, there's. we have alimerian rapally lenny you are say on the cland. we deep cliin of could kisial?\n",
        "moe_szyslak: pelt?\n",
        "moe_szyslak: patchine seech bute. i'd qraint alova?\n",
        "ape_mak_joevebon: you dunger sexsarffally. we beer armies!\n",
        "moe_szyslak: it's einatery two pieding chance.\n",
        "corley: that possich differ you a wondlet (necvoused!\n",
        "moe_szyslak: moe, there's gofthis hasply chanta (confestefive\n",
        "\n",
        "20 Epochs, temperature=0.2\n",
        "\n",
        "as the two-slit experiment has shown the best drink the bar that a thing a beer.\n",
        "moe_szyslak: (singing) i want to say the bar that see a beer.\n",
        "moe_szyslak: (singing) i don't want to see a man a back and the bartender secret of the too the bar love that see the poor and the bar that a minute.\n",
        "moe_szyslak: (sighs) hey, hey, i want to tell you and the beer with me.\n",
        "moe_szyslak: (confing and self) i can't be so beer to the bartender and the bar that to make a money to the bartender that in the wallan says a bar that a buy the secret a\n",
        "\n",
        "20 Epochs, temperature=0.7\n",
        "\n",
        "as the two-slit experiment has shown to the bar?\n",
        "moe_szyslak: yeah, i love you to shouldn have to pen the car on the eity course i got tooked was a blumble.\n",
        "stillwater: you got the pooz.\n",
        "lenny_leonard: you kneeg a little god here chumes.\n",
        "homer_simpson: (worrice) \"bellon--po name. (beat) what am i gorna god!\n",
        "moe_szyslak: (into homer) homer, we're alway / we got the once arvestane. (pleass girls) i let you stupid to could you think i'm not say right. these of sold the would never be a lothers help to two the jraces game with a speci\n",
        "\n",
        "20 Epochs, temperature=0.2\n",
        "\n",
        "as the two-slit experiment has shown.\n",
        "bar_ra_bad any: i did the poot a bicks. too promocs of felmar little \"cance after off end it!\n",
        "homer_simpson: (napamly) food is sure the swell) you haven kermanthe he's file small kinds on the alwonch to the outss. i thank right till joy, you heard that for yaks the exp.\n",
        "homer_simpson: this is donswes-hilg now look just laugh, here'se wartle pennable.\n",
        "marge_simpson: (wishing up to my problemping that on a douph pen-tho festing like twan's boy? o'lloct with keep ofd never the tratent fan't did, \n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP2e8_Qlc7qM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}